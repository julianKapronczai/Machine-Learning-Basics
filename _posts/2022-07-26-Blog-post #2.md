---
layout: post
title: Implementing Machine Learning(Blog post 2)
---

### Implementing Machine learning

First we will need an environment to work in, for this we will need to install Anaconda3. This will allow us to work in Jupyter notebook using Numpy, Pandas, Scikit-learn, and Matplotlib. Use the link bellow and follow along once it downloaded.

https://www.anaconda.com/products/distribution 
 ![Figure6]({{site.url}}/assets/images/anadown1.png)

Next up run the installer and follow along with the instructions. 

Click: Next

 ![Figure7]({{site.url}}/assets/images/anadown2.png)
Click: I Agree

 ![Figure8]({{site.url}}/assets/images/anadown3.png)
Install for: Just Me 
Then click: Next

 ![Figure9]({{site.url}}/assets/images/anadown4.png)
Select your desired destination folder then click: Next

 ![Figure10]({{site.url}}/assets/images/anadown5.png)
Leave the two boxes un-checked and click: Install

 ![Figure11]({{site.url}}/assets/images/anadown6.png)


The goal of this portion of the blog is to get a better understanding of how machine learning is implemented. To do so I will run you through some very simple examples of the tools we will use before we learn about implementing machine learning models properly.

Please follow the steps bellow and we will be good to get started with the examples:

1.Open up the Anaconda Navigator:
 
 ![Figure12]({{site.url}}/assets/images/anarun1.png)
2.Then launch JupyterLab:

 ![Figure13]({{site.url}}/assets/images/anarunJup.png)
3.Your browser will open this window:

 ![Figure14]({{site.url}}/assets/images/anarun2.png)
4.You now want to click this blue '+' button:

 ![Figure15]({{site.url}}/assets/images/newanaproj.png)
5.Click the Python 3 button under the Notebook section:

 ![Figure16]({{site.url}}/assets/images/newanaproj2.png)
You are now ready to start coding in Python 3, as well as work with machine learning.


REALLY IMPORTANT NOTE!!!!
To run the code blocks you write you will need to press the 'shift' key + the 'enter' key.

Now I’m not going to teach you Python as a language but really quick I’m going to mention some of the tools we will be using for the coding examples. To start off all of our examples we are going to be importing Numpy, Pandas, matplotlib, and seaborn


Numpy is a very useful package containing n-dimensional arrays and tool to integrate c and c++. Pandas provides us with a package to analyses and manipulate data structures. Matplotlib provides us with a library that allows us to visualize the data we will be working with. Lastly we will be using Seaborn which is another data visualization library, its based on matplot and provides further ways to visualize the data. 

You will want to start off almost any project by importing these libraries as they are core performers for anyone working with machine learning.

Your import code should look like this:
![Figure17]({{site.url}}/assets/images/imp1.png)


The first example of machine learning implementation will be a regression example. The goal of this is to become more familiar with regression models. We will be using some sample data about concrete mixtures to try and predict the strength of different concrete mixtures using a regression model.

Make sure the libraries above are imported in you code. 

We will now define the functions we will be using. Root-mean squared error (rms) will be used as our scoring function. An optimal score for rms is 0, the larger the number gets the worse the performance of a model. With that said in scikit-learn we can only use maximization. So we will have to maximize the negative rms, scikit-learn does provide a scoring function we can use here neg_root_mean_squared_error. We will also calculate the score for the model using cross-validation this score will be the rms.

Here is the code you will need. 
![Figure18]({{site.url}}/assets/images/imp2.png)

Now we need to load the data we will be working with. The concrete data you can find at this link: https://www.scikit-yb.org/en/latest/api/datasets/concrete.html
To get more info on this data set we will need to print out the README of the concrete dataset. To do so we need to load the dataset object using return_dataset=True. 
![Figure19]({{site.url}}/assets/images/imp3.png)

Now that we have information on the dataset, we can now load the concrete dataset into feature matrix 'X' and target vector 'y'
![Figure20]({{site.url}}/assets/images/imp4.png)
We now can see what our data actually looks like so lets print out the X.min() and X.max()
![Figure21]({{site.url}}/assets/images/imp5.png)
As nice as that is we can use seaborn to visualize this data a little bit better. Using the code bellow you can print out a heatmap of all of features in our dataframe
![Figure22]({{site.url}}/assets/images/imp6.png)
Now we need to create our traning and testing datasets. To do that we will use scikit-learn train_test_split() with the parameters random_state=37, test_size=0.2, split X and y into training and test sets.
![Figure23]({{site.url}}/assets/images/imp7.png)
Comparing models with cross-validation allows us to establish which model will be better for our use case. We are going to use 2 models for this LinearRegression,  RandomForestRegressor(random_state64) and GradientBoostingRegressor(random_state79). We will use seven fold cross-validation 

To iterate this list we need to get the negative root mean squared error. We can get the negRMS with get_regressor_neg_rms() function and print out the results to 2 decimal places.
![Figure24]({{site.url}}/assets/images/imp8.png)

All of those models had some problems with over and underfitting as shown by the printed results. Which means we need to find a better model. 

To do so we will use the RandomForestRegressor(random_state=64) again but find a better combination of max_depth from a list of [10, 15, 20] and n_estimators from a list of [50, 100, 150] 

Again we will use the get_regressor_neg_rms() function to print out our results to 2 decimal places. 
![Figure20]({{site.url}}/assets/images/imp9.png)

As we can see the highest validation score of -4.93 came from max_depth=20 and n_estimators=150 

With our model decided on we now will retrain the superior model. We will create a new RandomForestRegressor(random_state=64) with the best max_pair and n_estimators, then train it on all of our training data. 
![Figure20]({{site.url}}/assets/images/imp10.png)

Now that our model is trained, we can evaluate how it performs and see what our root mean-squared error(rmse) result is.
![Figure20]({{site.url}}/assets/images/imp11.png)
As we can see our training rmse is 0.986 and our testing rmse is 0.913. 
So our training root mean squared error is 98.6% accurate, and our testing root mean squared error is 91.3% accurate. 

Lets get a better visualization of what that looks like using a scatterplot that shows predicted strength on the x axis, and actual strength on the y axis. That way we can see where our errors were made.

![Figure20]({{site.url}}/assets/images/imp12.png)


The regression example above is a good introduction into the machine learning process. First we create our training and test splits, then we pick out our model using cross validation, we then receive a final score on the initial split. Also, throughout the process we played around with some data visualization to further our understanding of what we are working with. 

Next up is a classification problem. This time using data about poisonous and non-poisonous mushrooms.

This time we are going to be working with a dataset consisting of poisonous and non poisonous mushrooms. The goal is to predict which mushrooms are safe to eat and classify them accordingly. We will have our edible mushrooms as a negative class and our poisonous mushrooms as a positive class. With this we require a high recall score while maintaining an acceptable precision on our model. 

So to start off as always we need to import our libraries

![Figure21]({{site.url}}/assets/images/import.png)

Now we are going to import mglearn. We are going to follow the workflow displayed bellow after you run this code

![Figure22]({{site.url}}/assets/images/mglearn.png)

As you can see above we will need to split our dataset, cross-validate, and train our best performing model before its evaluated against out test data.

Now we are ready to define our functions. We need our parameters to include our model classifier, feature matrix, target vector, scoring string, and cv fold integer. We will then need to return the mean training score, and mean validation score. 

![Figure23]({{site.url}}/assets/images/function1.png)

Now we can define our plot_grid_search_results, this will let us plot grids with two hyperparameters, and make heatmap plots of test scores. For parameters we will need grid_search a fitted GridSearchCV object. This will use mglearn.tools.heatmatp() for plotting.

![Figure24]({{site.url}}/assets/images/function2.png)

Lastly we have to define our plot_confusion_matrix this will let us create heatmap plots of the confusion matrix itself. The confusion matrix will let us view the true values on the y axis and the predicted values on our x axis. For that we will need parameters, y_actual which is our ground truth label vector, y_pred our predicted label vector, labels our class names for plotting, and a title. this uses sklearn.metrict.confusion_matrix

![Figure25]({{site.url}}/assets/images/function3.png)

We have defined our functions which means the next step is to load the data we will be using. Using the yellowbrick load_mushroom() function we can load our dataset into feature matrix 'X' and target vector 'y'.

![Figure26]({{site.url}}/assets/images/load.png)

We can now visualize the data to get a better idea of the categorized features and target classes we are working with. 

To do this we will use seaborn countplot(). 

![Figure27]({{site.url}}/assets/images/barplot.png)

Now we will be doing some preprocessing of the data we have. This dataset consists of features that are discrete and nomial, as such they need to be encoded. To do this we will be using OneHotEncoder to do the encoding for us. For this we want to only use the 'X' variable into an encoded X_enc. 

![Figure28]({{site.url}}/assets/images/onehot.png)

The target vectors in this data set are also discrete and nomial, to help with that we are going to use a LableEncoder to convert strings into integers. We only use the 'y' variables and convert 'y' to y_enc.

![Figure29]({{site.url}}/assets/images/labelen.png)

Time to create our training and testing datasets. We will use train_test_split() with the parameters random_state=37, test_size=0.2, split X_enc and y_enc into training and test datasets.

![Figure30]({{site.url}}/assets/images/traintest.png)

We have everything we need to start cross-validating we are going to use five models from the sklearn library, compute the average precision of each of them using get_classifier_cv_score(). Then rank the models based on the validation average precision, we are looking for the best fit for the data here. Finally print out the ranked models and validation scores with 3 decimal places. 

![Figure31]({{site.url}}/assets/images/cv.png)

Do a grid search using GridSearchCV for the RandomForestClassifier(random_state=55). What we are going to do with that is tune our hyperparameters. We will do a seven fold  cross-validation, GridSearchCV has a n_jobs parameter that lets us run a search in parallel, as such try setting it to the number of CPU cores you have and it will run better.

Set your hyperparameters and values to:
'n_estimators':[300, 500, 700, 1000]
'max_depth': [7, 9, 11, 13] 

![Figure32]({{site.url}}/assets/images/RFgs.png)

Now print the results of the grid search using print_grid_search_result()

![Figure33]({{site.url}}/assets/images/RFgs1.png)

Plot out the grid search result as well 

![Figure34]({{site.url}}/assets/images/RFfgs2.png)

We are now going to perform grid search cross-validation on GradientBoostingClassifier and SVC. Starting off with GradientBoostingClassifier we will again use a seven fold cross-validation and average_precision as the scoring funtion. Remember to set n_jobs to the number of CPU cores you have.

Use these hyperparameters and values:
'n_estimators': [50, 100, 200]
'learning_rates': [0.001, 0.01, 0.1, 1.0]

![Figure35]({{site.url}}/assets/images/GBgs.png)

Now print out the grid search results and then plot the grid search. 

![Figure36]({{site.url}}/assets/images/GBgs1.png)
![Figure37]({{site.url}}/assets/images/GBgs2.png)

To finish off the grid search cross-validation we need to perform it on the SVC model. 

Not to sound like a broken record but you know the drill, seven fold cross-validation, average_precision for the scoring function. n_jobs set to cpu cores. 

Here are your hyperparameter and values
'C': [0.0001, 0.001, 0.01, 0.1]
'gamma': [0.1, 1, 10, 100]
![Figure38]({{site.url}}/assets/images/SVCgs.png)

Now print those super cool and fun grid search results and plot that extra spicy grid search.
![Figure39]({{site.url}}/assets/images/SVCgs1.png)
![Figure40]({{site.url}}/assets/images/SVCgs2.png)

So what does all of that tell us? well we now have the training and validation scores of the three models we tunes. our results are:

RandomForestClassifier: Training Score = 0.806, Validation Score = 0.794 with {'max_depth': 11, 'n_estimators': 700}

GradientBoostingClassfier: Training Score = 0.806, Validation Score = 0.795 with {'learning_rate': 0.1, 'n_estimators': 100}

SVC: Training Score = 0.779, Validation Score = 0.772 with {'C': 0.0001, 'gamma': 10}

The result from the GradientBoostingClassifier has the best performance for our use case. 

We will be using the training dataset and the highest performing GradientBoostingClassifier from the grid search above.  

For this we will need to calculate the predicted probabilities using cross_val_predict() with the parameters cv=7, method='predict_proba'. Then plot the precision-recall curve indicating where the default threshold 0.5 is. 

Make sure to include a legend and axis label.

![Figure41]({{site.url}}/assets/images/threshold.png)

We need to get a high recall value. So we need to determine the probability threshold to achieve a recall value higher than 0.999. Remember to store this value and print it.

![Figure42]({{site.url}}/assets/images/999.png)

Now we can re-train the model that had the best results. that one being the GradientBoostingClassifier. So take the Best model from above and re-train it on the training dataset.

![Figure43]({{site.url}}/assets/images/retrainbest.png)

Now we can start to evaluate our model with our testing dataset. We need to print out our calssification report and plot the confusion matrix using plot_confusion_matrix(). The plot need to have class labels and a title.

![Figure44]({{site.url}}/assets/images/evaldefault.png)

Lastly we can evaluate our model using the new threshold from step 7.

![Figure45]({{site.url}}/assets/images/evalnew.png)

The default threshold has:
Precision = 0.71
Recall = 0.63
Accuracy = 0.70
Threshold = 288 False Negatives

The optimal threshold has:
Precision = 0.51
Recall = 1.00
Accuracy = 0.54
Threshold = 0 False Negatives.

Our final model has a result of around 10% of the mushrooms being identified as not poisonous, and none of the poisonous mushrooms being incoreclly calssified. All and all that is a great success as our model does what it sets out too which is correctly classify poisonous mushrooms. This provides a possible real world example of how machine learning can benefit society. This also provides a great example for how we can use machine learning to resolve classification problems, along side showing off how we can manipulate data and our models even further to yield better results. 

Thank you, hopefully this helps your understanding of how machine learning can be implemented. 


<sub>Reference List:

1. Andreas C. Müller, Sarah Guido - Introduction to Machine Learning with Python_ A Guide for Data Scientists-O’Reilly Media (2016)
2. David Cooksley, Human Resource, Mentor
3. P. Bozelos, “World wide ✈️ machine learning,” World Wide ML. [Online]. Available: https://www.world-wide.org/ML/. [Accessed: 17-Jun-2022]. 
4. “Supervised and unsupervised machine learning - explained through real world examples,” Omdena, 21-Mar-2022. [Online]. Available: https://omdena.com/blog/supervised-and-unsupervised-machine-learning/. [Accessed: 17-Jun-2022]. 
5. “Clustering in machine learning,” GeeksforGeeks, 18-May-2022. [Online]. Available: https://www.geeksforgeeks.org/clustering-in-machine-learning/. [Accessed: 17-Jun-2022].  
6. Yeh, I-C. "Modeling of strength of high-performance concrete using artificial neural networks." Cement and Concrete research 28.12 (1998): 1797-1808.
</sub>
